{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyPuapDlQGKiDT+tZ87VBpDv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WZGR0d9jCy1k","executionInfo":{"status":"ok","timestamp":1747231693414,"user_tz":-330,"elapsed":447891,"user":{"displayName":"Ruchira Gamage","userId":"11748974728532815800"}},"outputId":"b21f5a02-f601-42ce-82d1-2ecc95fca518"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.4/303.4 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install -q llama-cpp-python pypdf sentence-transformers faiss-cpu pdfminer.six tqdm PyPDF2\n","!wget -q https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGUF/resolve/main/llama-2-7b-chat.Q4_K_M.gguf"]},{"cell_type":"markdown","source":["# Model Setep\n","\n"],"metadata":{"id":"hEDSYUt6C8Oo"}},{"cell_type":"code","source":["from llama_cpp import Llama\n","import os\n","\n","# Initialize the model\n","llm = Llama(\n","    model_path=\"llama-2-7b-chat.Q4_K_M.gguf\",\n","    n_ctx=2048,\n","    n_threads=4,\n","    n_gpu_layers=40 if 'CUDA_VISIBLE_DEVICES' in os.environ else 0\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ktXliok1DE34","executionInfo":{"status":"ok","timestamp":1747232170776,"user_tz":-330,"elapsed":14082,"user":{"displayName":"Ruchira Gamage","userId":"11748974728532815800"}},"outputId":"729a078a-8d23-4e64-d964-35602149b6f2"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from llama-2-7b-chat.Q4_K_M.gguf (version GGUF V2)\n","llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n","llama_model_loader: - kv   0:                       general.architecture str              = llama\n","llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n","llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n","llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n","llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n","llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n","llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n","llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n","llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n","llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n","llama_model_loader: - kv  10:                          general.file_type u32              = 15\n","llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n","llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n","llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n","llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n","llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n","llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n","llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n","llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n","llama_model_loader: - type  f32:   65 tensors\n","llama_model_loader: - type q4_K:  193 tensors\n","llama_model_loader: - type q6_K:   33 tensors\n","print_info: file format = GGUF V2\n","print_info: file type   = Q4_K - Medium\n","print_info: file size   = 3.80 GiB (4.84 BPW) \n","init_tokenizer: initializing tokenizer for type 1\n","load: control token:      2 '</s>' is not marked as EOG\n","load: control token:      1 '<s>' is not marked as EOG\n","load: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n","load: special tokens cache size = 3\n","load: token to piece cache size = 0.1684 MB\n","print_info: arch             = llama\n","print_info: vocab_only       = 0\n","print_info: n_ctx_train      = 4096\n","print_info: n_embd           = 4096\n","print_info: n_layer          = 32\n","print_info: n_head           = 32\n","print_info: n_head_kv        = 32\n","print_info: n_rot            = 128\n","print_info: n_swa            = 0\n","print_info: n_swa_pattern    = 1\n","print_info: n_embd_head_k    = 128\n","print_info: n_embd_head_v    = 128\n","print_info: n_gqa            = 1\n","print_info: n_embd_k_gqa     = 4096\n","print_info: n_embd_v_gqa     = 4096\n","print_info: f_norm_eps       = 0.0e+00\n","print_info: f_norm_rms_eps   = 1.0e-06\n","print_info: f_clamp_kqv      = 0.0e+00\n","print_info: f_max_alibi_bias = 0.0e+00\n","print_info: f_logit_scale    = 0.0e+00\n","print_info: f_attn_scale     = 0.0e+00\n","print_info: n_ff             = 11008\n","print_info: n_expert         = 0\n","print_info: n_expert_used    = 0\n","print_info: causal attn      = 1\n","print_info: pooling type     = 0\n","print_info: rope type        = 0\n","print_info: rope scaling     = linear\n","print_info: freq_base_train  = 10000.0\n","print_info: freq_scale_train = 1\n","print_info: n_ctx_orig_yarn  = 4096\n","print_info: rope_finetuned   = unknown\n","print_info: ssm_d_conv       = 0\n","print_info: ssm_d_inner      = 0\n","print_info: ssm_d_state      = 0\n","print_info: ssm_dt_rank      = 0\n","print_info: ssm_dt_b_c_rms   = 0\n","print_info: model type       = 7B\n","print_info: model params     = 6.74 B\n","print_info: general.name     = LLaMA v2\n","print_info: vocab type       = SPM\n","print_info: n_vocab          = 32000\n","print_info: n_merges         = 0\n","print_info: BOS token        = 1 '<s>'\n","print_info: EOS token        = 2 '</s>'\n","print_info: UNK token        = 0 '<unk>'\n","print_info: LF token         = 13 '<0x0A>'\n","print_info: EOG token        = 2 '</s>'\n","print_info: max token length = 48\n","load_tensors: loading model tensors, this can take a while... (mmap = true)\n","load_tensors: layer   0 assigned to device CPU, is_swa = 0\n","load_tensors: layer   1 assigned to device CPU, is_swa = 0\n","load_tensors: layer   2 assigned to device CPU, is_swa = 0\n","load_tensors: layer   3 assigned to device CPU, is_swa = 0\n","load_tensors: layer   4 assigned to device CPU, is_swa = 0\n","load_tensors: layer   5 assigned to device CPU, is_swa = 0\n","load_tensors: layer   6 assigned to device CPU, is_swa = 0\n","load_tensors: layer   7 assigned to device CPU, is_swa = 0\n","load_tensors: layer   8 assigned to device CPU, is_swa = 0\n","load_tensors: layer   9 assigned to device CPU, is_swa = 0\n","load_tensors: layer  10 assigned to device CPU, is_swa = 0\n","load_tensors: layer  11 assigned to device CPU, is_swa = 0\n","load_tensors: layer  12 assigned to device CPU, is_swa = 0\n","load_tensors: layer  13 assigned to device CPU, is_swa = 0\n","load_tensors: layer  14 assigned to device CPU, is_swa = 0\n","load_tensors: layer  15 assigned to device CPU, is_swa = 0\n","load_tensors: layer  16 assigned to device CPU, is_swa = 0\n","load_tensors: layer  17 assigned to device CPU, is_swa = 0\n","load_tensors: layer  18 assigned to device CPU, is_swa = 0\n","load_tensors: layer  19 assigned to device CPU, is_swa = 0\n","load_tensors: layer  20 assigned to device CPU, is_swa = 0\n","load_tensors: layer  21 assigned to device CPU, is_swa = 0\n","load_tensors: layer  22 assigned to device CPU, is_swa = 0\n","load_tensors: layer  23 assigned to device CPU, is_swa = 0\n","load_tensors: layer  24 assigned to device CPU, is_swa = 0\n","load_tensors: layer  25 assigned to device CPU, is_swa = 0\n","load_tensors: layer  26 assigned to device CPU, is_swa = 0\n","load_tensors: layer  27 assigned to device CPU, is_swa = 0\n","load_tensors: layer  28 assigned to device CPU, is_swa = 0\n","load_tensors: layer  29 assigned to device CPU, is_swa = 0\n","load_tensors: layer  30 assigned to device CPU, is_swa = 0\n","load_tensors: layer  31 assigned to device CPU, is_swa = 0\n","load_tensors: layer  32 assigned to device CPU, is_swa = 0\n","load_tensors: tensor 'token_embd.weight' (q4_K) (and 98 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n","load_tensors:  CPU_AARCH64 model buffer size =  2943.00 MiB\n","load_tensors:   CPU_Mapped model buffer size =  3891.24 MiB\n","repack: repack tensor blk.0.attn_q.weight with q4_K_8x8\n","repack: repack tensor blk.0.attn_k.weight with q4_K_8x8\n","repack: repack tensor blk.0.attn_output.weight with q4_K_8x8\n","repack: repack tensor blk.0.ffn_gate.weight with q4_K_8x8\n",".repack: repack tensor blk.0.ffn_up.weight with q4_K_8x8\n","repack: repack tensor blk.1.attn_q.weight with q4_K_8x8\n",".repack: repack tensor blk.1.attn_k.weight with q4_K_8x8\n","repack: repack tensor blk.1.attn_output.weight with q4_K_8x8\n","repack: repack tensor blk.1.ffn_gate.weight with q4_K_8x8\n",".repack: repack tensor blk.1.ffn_up.weight with q4_K_8x8\n","repack: repack tensor blk.2.attn_q.weight with q4_K_8x8\n",".repack: repack tensor blk.2.attn_k.weight with q4_K_8x8\n","repack: repack tensor blk.2.attn_output.weight with q4_K_8x8\n","repack: repack tensor blk.2.ffn_gate.weight with q4_K_8x8\n",".repack: repack tensor blk.2.ffn_up.weight with q4_K_8x8\n","repack: repack tensor blk.3.attn_q.weight with q4_K_8x8\n",".repack: repack tensor blk.3.attn_k.weight with q4_K_8x8\n","repack: repack tensor blk.3.attn_v.weight with q4_K_8x8\n","repack: repack tensor blk.3.attn_output.weight with q4_K_8x8\n","repack: repack tensor blk.3.ffn_gate.weight with q4_K_8x8\n",".repack: repack tensor blk.3.ffn_down.weight with q4_K_8x8\n","repack: repack tensor blk.3.ffn_up.weight with q4_K_8x8\n",".repack: repack tensor blk.4.attn_q.weight with q4_K_8x8\n","repack: repack tensor blk.4.attn_k.weight with q4_K_8x8\n",".repack: repack tensor blk.4.attn_output.weight with q4_K_8x8\n","repack: repack tensor blk.4.ffn_gate.weight with q4_K_8x8\n","repack: repack tensor blk.4.ffn_up.weight with q4_K_8x8\n",".repack: repack tensor blk.5.attn_q.weight with q4_K_8x8\n","repack: repack tensor blk.5.attn_k.weight with q4_K_8x8\n",".repack: repack tensor blk.5.attn_v.weight with q4_K_8x8\n","repack: repack tensor blk.5.attn_output.weight with q4_K_8x8\n","repack: repack tensor blk.5.ffn_gate.weight with q4_K_8x8\n",".repack: repack tensor blk.5.ffn_down.weight with q4_K_8x8\n","repack: repack tensor blk.5.ffn_up.weight with q4_K_8x8\n",".repack: repack tensor blk.6.attn_q.weight with q4_K_8x8\n","repack: repack tensor blk.6.attn_k.weight with q4_K_8x8\n","repack: repack tensor blk.6.attn_v.weight with q4_K_8x8\n",".repack: repack tensor blk.6.attn_output.weight with q4_K_8x8\n","repack: repack tensor blk.6.ffn_gate.weight with q4_K_8x8\n","repack: repack tensor blk.6.ffn_down.weight with q4_K_8x8\n",".repack: repack tensor blk.6.ffn_up.weight with q4_K_8x8\n",".repack: repack tensor blk.7.attn_q.weight with q4_K_8x8\n","repack: repack tensor blk.7.attn_k.weight with q4_K_8x8\n","repack: repack tensor blk.7.attn_output.weight with q4_K_8x8\n","repack: repack tensor blk.7.ffn_gate.weight with q4_K_8x8\n",".repack: repack tensor blk.7.ffn_up.weight with q4_K_8x8\n",".repack: repack tensor blk.8.attn_q.weight with q4_K_8x8\n","repack: repack tensor blk.8.attn_k.weight with q4_K_8x8\n","repack: repack tensor blk.8.attn_v.weight with q4_K_8x8\n","repack: repack tensor blk.8.attn_output.weight with q4_K_8x8\n","repack: repack tensor blk.8.ffn_gate.weight with q4_K_8x8\n",".repack: repack tensor blk.8.ffn_down.weight with q4_K_8x8\n",".repack: repack tensor blk.8.ffn_up.weight with q4_K_8x8\n","repack: repack tensor blk.9.attn_q.weight with q4_K_8x8\n",".repack: repack tensor blk.9.attn_k.weight with q4_K_8x8\n","repack: repack tensor blk.9.attn_v.weight with q4_K_8x8\n","repack: repack tensor blk.9.attn_output.weight with q4_K_8x8\n","repack: repack tensor blk.9.ffn_gate.weight with q4_K_8x8\n",".repack: repack tensor blk.9.ffn_down.weight with q4_K_8x8\n",".repack: repack tensor blk.9.ffn_up.weight with q4_K_8x8\n","repack: repack tensor blk.10.attn_q.weight with q4_K_8x8\n","repack: repack tensor blk.10.attn_k.weight with q4_K_8x8\n",".repack: repack tensor blk.10.attn_output.weight with q4_K_8x8\n","repack: repack tensor blk.10.ffn_gate.weight with q4_K_8x8\n","repack: repack tensor blk.10.ffn_up.weight with q4_K_8x8\n",".repack: repack tensor blk.11.attn_q.weight with q4_K_8x8\n","repack: repack tensor blk.11.attn_k.weight with q4_K_8x8\n",".repack: repack tensor blk.11.attn_output.weight with q4_K_8x8\n","repack: repack tensor blk.11.ffn_gate.weight with q4_K_8x8\n","repack: repack tensor blk.11.ffn_up.weight with q4_K_8x8\n",".repack: repack tensor blk.12.attn_q.weight with q4_K_8x8\n","repack: repack tensor blk.12.attn_k.weight with q4_K_8x8\n","repack: repack tensor blk.12.attn_v.weight with q4_K_8x8\n",".repack: repack tensor blk.12.attn_output.weight with q4_K_8x8\n","repack: repack tensor blk.12.ffn_gate.weight with q4_K_8x8\n",".repack: repack tensor blk.12.ffn_down.weight with q4_K_8x8\n","repack: repack tensor blk.12.ffn_up.weight with q4_K_8x8\n",".repack: repack tensor blk.13.attn_q.weight with q4_K_8x8\n","repack: repack tensor blk.13.attn_k.weight with q4_K_8x8\n","repack: repack tensor blk.13.attn_v.weight with q4_K_8x8\n","repack: repack tensor blk.13.attn_output.weight with q4_K_8x8\n",".repack: repack tensor blk.13.ffn_gate.weight with q4_K_8x8\n","repack: repack tensor blk.13.ffn_down.weight with q4_K_8x8\n",".repack: repack tensor blk.13.ffn_up.weight with q4_K_8x8\n",".repack: repack tensor blk.14.attn_q.weight with q4_K_8x8\n","repack: repack tensor blk.14.attn_k.weight with q4_K_8x8\n","repack: repack tensor blk.14.attn_output.weight with q4_K_8x8\n","repack: repack tensor blk.14.ffn_gate.weight with q4_K_8x8\n",".repack: repack tensor blk.14.ffn_up.weight with q4_K_8x8\n",".repack: repack tensor blk.15.attn_q.weight with q4_K_8x8\n","repack: repack tensor blk.15.attn_k.weight with q4_K_8x8\n","repack: repack tensor blk.15.attn_v.weight with q4_K_8x8\n","repack: repack tensor blk.15.attn_output.weight with q4_K_8x8\n","repack: repack tensor blk.15.ffn_gate.weight with q4_K_8x8\n",".repack: repack tensor blk.15.ffn_down.weight with q4_K_8x8\n",".repack: repack tensor blk.15.ffn_up.weight with q4_K_8x8\n","repack: repack tensor blk.16.attn_q.weight with q4_K_8x8\n",".repack: repack tensor blk.16.attn_k.weight with q4_K_8x8\n","repack: repack tensor blk.16.attn_v.weight with q4_K_8x8\n","repack: repack tensor blk.16.attn_output.weight with q4_K_8x8\n","repack: repack tensor blk.16.ffn_gate.weight with q4_K_8x8\n",".repack: repack tensor blk.16.ffn_down.weight with q4_K_8x8\n","repack: repack tensor blk.16.ffn_up.weight with q4_K_8x8\n",".repack: repack tensor blk.17.attn_q.weight with q4_K_8x8\n","repack: repack tensor blk.17.attn_k.weight with q4_K_8x8\n",".repack: repack tensor blk.17.attn_output.weight with q4_K_8x8\n","repack: repack tensor blk.17.ffn_gate.weight with q4_K_8x8\n","repack: repack tensor blk.17.ffn_up.weight with q4_K_8x8\n",".repack: repack tensor blk.18.attn_q.weight with q4_K_8x8\n","repack: repack tensor blk.18.attn_k.weight with q4_K_8x8\n",".repack: repack tensor blk.18.attn_v.weight with q4_K_8x8\n","repack: repack tensor blk.18.attn_output.weight with q4_K_8x8\n","repack: repack tensor blk.18.ffn_gate.weight with q4_K_8x8\n",".repack: repack tensor blk.18.ffn_down.weight with q4_K_8x8\n","repack: repack tensor blk.18.ffn_up.weight with q4_K_8x8\n",".repack: repack tensor blk.19.attn_q.weight with q4_K_8x8\n","repack: repack tensor blk.19.attn_k.weight with q4_K_8x8\n","repack: repack tensor blk.19.attn_v.weight with q4_K_8x8\n",".repack: repack tensor blk.19.attn_output.weight with q4_K_8x8\n","repack: repack tensor blk.19.ffn_gate.weight with q4_K_8x8\n","repack: repack tensor blk.19.ffn_down.weight with q4_K_8x8\n",".repack: repack tensor blk.19.ffn_up.weight with q4_K_8x8\n",".repack: repack tensor blk.20.attn_q.weight with q4_K_8x8\n","repack: repack tensor blk.20.attn_k.weight with q4_K_8x8\n","repack: repack tensor blk.20.attn_v.weight with q4_K_8x8\n","repack: repack tensor blk.20.attn_output.weight with q4_K_8x8\n",".repack: repack tensor blk.20.ffn_gate.weight with q4_K_8x8\n","repack: repack tensor blk.20.ffn_down.weight with q4_K_8x8\n",".repack: repack tensor blk.20.ffn_up.weight with q4_K_8x8\n","repack: repack tensor blk.21.attn_q.weight with q4_K_8x8\n",".repack: repack tensor blk.21.attn_k.weight with q4_K_8x8\n","repack: repack tensor blk.21.attn_v.weight with q4_K_8x8\n","repack: repack tensor blk.21.attn_output.weight with q4_K_8x8\n","repack: repack tensor blk.21.ffn_gate.weight with q4_K_8x8\n",".repack: repack tensor blk.21.ffn_down.weight with q4_K_8x8\n",".repack: repack tensor blk.21.ffn_up.weight with q4_K_8x8\n","repack: repack tensor blk.22.attn_q.weight with q4_K_8x8\n","repack: repack tensor blk.22.attn_k.weight with q4_K_8x8\n",".repack: repack tensor blk.22.attn_output.weight with q4_K_8x8\n","repack: repack tensor blk.22.ffn_gate.weight with q4_K_8x8\n",".repack: repack tensor blk.22.ffn_up.weight with q4_K_8x8\n","repack: repack tensor blk.23.attn_q.weight with q4_K_8x8\n","repack: repack tensor blk.23.attn_k.weight with q4_K_8x8\n",".repack: repack tensor blk.23.attn_v.weight with q4_K_8x8\n","repack: repack tensor blk.23.attn_output.weight with q4_K_8x8\n","repack: repack tensor blk.23.ffn_gate.weight with q4_K_8x8\n",".repack: repack tensor blk.23.ffn_down.weight with q4_K_8x8\n","repack: repack tensor blk.23.ffn_up.weight with q4_K_8x8\n",".repack: repack tensor blk.24.attn_q.weight with q4_K_8x8\n","repack: repack tensor blk.24.attn_k.weight with q4_K_8x8\n","repack: repack tensor blk.24.attn_output.weight with q4_K_8x8\n",".repack: repack tensor blk.24.ffn_gate.weight with q4_K_8x8\n","repack: repack tensor blk.24.ffn_up.weight with q4_K_8x8\n",".repack: repack tensor blk.25.attn_q.weight with q4_K_8x8\n","repack: repack tensor blk.25.attn_k.weight with q4_K_8x8\n","repack: repack tensor blk.25.attn_v.weight with q4_K_8x8\n",".repack: repack tensor blk.25.attn_output.weight with q4_K_8x8\n","repack: repack tensor blk.25.ffn_gate.weight with q4_K_8x8\n","repack: repack tensor blk.25.ffn_down.weight with q4_K_8x8\n",".repack: repack tensor blk.25.ffn_up.weight with q4_K_8x8\n",".repack: repack tensor blk.26.attn_q.weight with q4_K_8x8\n","repack: repack tensor blk.26.attn_k.weight with q4_K_8x8\n","repack: repack tensor blk.26.attn_v.weight with q4_K_8x8\n","repack: repack tensor blk.26.attn_output.weight with q4_K_8x8\n",".repack: repack tensor blk.26.ffn_gate.weight with q4_K_8x8\n","repack: repack tensor blk.26.ffn_down.weight with q4_K_8x8\n",".repack: repack tensor blk.26.ffn_up.weight with q4_K_8x8\n","repack: repack tensor blk.27.attn_q.weight with q4_K_8x8\n",".repack: repack tensor blk.27.attn_k.weight with q4_K_8x8\n","repack: repack tensor blk.27.attn_output.weight with q4_K_8x8\n","repack: repack tensor blk.27.ffn_gate.weight with q4_K_8x8\n",".repack: repack tensor blk.27.ffn_up.weight with q4_K_8x8\n","repack: repack tensor blk.28.attn_q.weight with q4_K_8x8\n",".repack: repack tensor blk.28.attn_k.weight with q4_K_8x8\n","repack: repack tensor blk.28.attn_output.weight with q4_K_8x8\n","repack: repack tensor blk.28.ffn_gate.weight with q4_K_8x8\n",".repack: repack tensor blk.28.ffn_up.weight with q4_K_8x8\n","repack: repack tensor blk.29.attn_q.weight with q4_K_8x8\n",".repack: repack tensor blk.29.attn_k.weight with q4_K_8x8\n","repack: repack tensor blk.29.attn_output.weight with q4_K_8x8\n","repack: repack tensor blk.29.ffn_gate.weight with q4_K_8x8\n",".repack: repack tensor blk.29.ffn_up.weight with q4_K_8x8\n","repack: repack tensor blk.30.attn_q.weight with q4_K_8x8\n","repack: repack tensor blk.30.attn_k.weight with q4_K_8x8\n",".repack: repack tensor blk.30.attn_output.weight with q4_K_8x8\n","repack: repack tensor blk.30.ffn_gate.weight with q4_K_8x8\n",".repack: repack tensor blk.30.ffn_up.weight with q4_K_8x8\n","repack: repack tensor blk.31.attn_q.weight with q4_K_8x8\n","repack: repack tensor blk.31.attn_k.weight with q4_K_8x8\n",".repack: repack tensor blk.31.attn_output.weight with q4_K_8x8\n","repack: repack tensor blk.31.ffn_gate.weight with q4_K_8x8\n",".repack: repack tensor blk.31.ffn_up.weight with q4_K_8x8\n","......................\n","llama_context: constructing llama_context\n","llama_context: n_seq_max     = 1\n","llama_context: n_ctx         = 2048\n","llama_context: n_ctx_per_seq = 2048\n","llama_context: n_batch       = 512\n","llama_context: n_ubatch      = 512\n","llama_context: causal_attn   = 1\n","llama_context: flash_attn    = 0\n","llama_context: freq_base     = 10000.0\n","llama_context: freq_scale    = 1\n","llama_context: n_ctx_per_seq (2048) < n_ctx_train (4096) -- the full capacity of the model will not be utilized\n","set_abort_callback: call\n","llama_context:        CPU  output buffer size =     0.12 MiB\n","create_memory: n_ctx = 2048 (padded)\n","llama_kv_cache_unified: kv_size = 2048, type_k = 'f16', type_v = 'f16', n_layer = 32, can_shift = 1, padding = 32\n","llama_kv_cache_unified: layer   0: dev = CPU\n","llama_kv_cache_unified: layer   1: dev = CPU\n","llama_kv_cache_unified: layer   2: dev = CPU\n","llama_kv_cache_unified: layer   3: dev = CPU\n","llama_kv_cache_unified: layer   4: dev = CPU\n","llama_kv_cache_unified: layer   5: dev = CPU\n","llama_kv_cache_unified: layer   6: dev = CPU\n","llama_kv_cache_unified: layer   7: dev = CPU\n","llama_kv_cache_unified: layer   8: dev = CPU\n","llama_kv_cache_unified: layer   9: dev = CPU\n","llama_kv_cache_unified: layer  10: dev = CPU\n","llama_kv_cache_unified: layer  11: dev = CPU\n","llama_kv_cache_unified: layer  12: dev = CPU\n","llama_kv_cache_unified: layer  13: dev = CPU\n","llama_kv_cache_unified: layer  14: dev = CPU\n","llama_kv_cache_unified: layer  15: dev = CPU\n","llama_kv_cache_unified: layer  16: dev = CPU\n","llama_kv_cache_unified: layer  17: dev = CPU\n","llama_kv_cache_unified: layer  18: dev = CPU\n","llama_kv_cache_unified: layer  19: dev = CPU\n","llama_kv_cache_unified: layer  20: dev = CPU\n","llama_kv_cache_unified: layer  21: dev = CPU\n","llama_kv_cache_unified: layer  22: dev = CPU\n","llama_kv_cache_unified: layer  23: dev = CPU\n","llama_kv_cache_unified: layer  24: dev = CPU\n","llama_kv_cache_unified: layer  25: dev = CPU\n","llama_kv_cache_unified: layer  26: dev = CPU\n","llama_kv_cache_unified: layer  27: dev = CPU\n","llama_kv_cache_unified: layer  28: dev = CPU\n","llama_kv_cache_unified: layer  29: dev = CPU\n","llama_kv_cache_unified: layer  30: dev = CPU\n","llama_kv_cache_unified: layer  31: dev = CPU\n","llama_kv_cache_unified:        CPU KV buffer size =  1024.00 MiB\n","llama_kv_cache_unified: KV self size  = 1024.00 MiB, K (f16):  512.00 MiB, V (f16):  512.00 MiB\n","llama_context: enumerating backends\n","llama_context: backend_ptrs.size() = 1\n","llama_context: max_nodes = 65536\n","llama_context: worst-case: n_tokens = 512, n_seqs = 1, n_outputs = 0\n","llama_context: reserving graph for n_tokens = 512, n_seqs = 1\n","llama_context: reserving graph for n_tokens = 1, n_seqs = 1\n","llama_context: reserving graph for n_tokens = 512, n_seqs = 1\n","llama_context:        CPU compute buffer size =   164.01 MiB\n","llama_context: graph nodes  = 1094\n","llama_context: graph splits = 1\n","CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | \n","Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.context_length': '4096', 'general.name': 'LLaMA v2', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '11008', 'llama.attention.layer_norm_rms_epsilon': '0.000001', 'llama.rope.dimension_count': '128', 'llama.attention.head_count': '32', 'tokenizer.ggml.bos_token_id': '1', 'llama.block_count': '32', 'llama.attention.head_count_kv': '32', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '15'}\n","Using fallback chat format: llama-2\n"]}]},{"cell_type":"markdown","source":["# PDF Processing"],"metadata":{"id":"LMV11iWaDKzR"}},{"cell_type":"code","source":["import PyPDF2\n","from io import BytesIO\n","from pdfminer.high_level import extract_text\n","from pdfminer.layout import LAParams\n","from pdfminer.high_level import extract_text_to_fp\n","\n","def pdf_to_text(file_bytes):\n","    \"\"\"Extract text from PDF using multiple methods\"\"\"\n","    text = \"\"\n","\n","    # Method 1: Try pdfminer first\n","    try:\n","        output = BytesIO()\n","        laparams = LAParams(line_margin=0.5)\n","        extract_text_to_fp(BytesIO(file_bytes), output, laparams=laparams)\n","        text = output.getvalue().decode('utf-8')\n","    except Exception as e:\n","        print(f\"pdfminer failed: {str(e)}\")\n","\n","    # Method 2: Fallback to PyPDF2\n","    if len(text) < 100:\n","        try:\n","            reader = PyPDF2.PdfReader(BytesIO(file_bytes))\n","            text = \"\\n\".join([page.extract_text() for page in reader.pages if page.extract_text()])\n","        except Exception as e:\n","            print(f\"PyPDF2 failed: {str(e)}\")\n","\n","    # Basic cleaning\n","    text = ' '.join(text.split())\n","    return text[:50000]  # Limit to 50k characters\n"],"metadata":{"id":"06qLMNrhDQRp","executionInfo":{"status":"ok","timestamp":1747232265544,"user_tz":-330,"elapsed":569,"user":{"displayName":"Ruchira Gamage","userId":"11748974728532815800"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["# Questions generating"],"metadata":{"id":"C3JlzDwODV5J"}},{"cell_type":"code","source":["from tqdm import tqdm\n","import gc\n","\n","def generate_questions_from_chunk(chunk):\n","    \"\"\"Generate questions from a text chunk\"\"\"\n","    prompt = f\"\"\"Generate 3 quiz questions from this text:\n","    {chunk}\n","\n","    Format each question like this:\n","    Q) [Question text]\n","    A) [Option A] B) [Option B] C) [Option C] D) [Option D]\n","    Answer: [Correct letter]\n","    Explanation: [Brief explanation]\n","    ---\n","    \"\"\"\n","\n","    try:\n","        response = llm.create_completion(\n","            prompt=prompt,\n","            max_tokens=1000,\n","            temperature=0.7,\n","            stop=[\"Q)\"]\n","        )\n","        return response['choices'][0]['text']\n","    except Exception as e:\n","        print(f\"Question generation failed: {str(e)}\")\n","        return \"\"\n","\n","def generate_quiz(text, num_questions=10):\n","    \"\"\"Main quiz generation function\"\"\"\n","    if not text:\n","        return []\n","\n","    chunk_size = 1500\n","    questions = []\n","\n","    # Process text in chunks\n","    for i in tqdm(range(0, len(text), chunk_size), desc=\"Processing text\"):\n","        chunk = text[i:i+chunk_size]\n","        if not chunk.strip():\n","            continue\n","\n","        generated = generate_questions_from_chunk(chunk)\n","        if generated:\n","            questions.extend([q.strip() for q in generated.split('---') if q.strip()])\n","\n","        if len(questions) >= num_questions:\n","            break\n","\n","        gc.collect()  # Help with memory management\n","\n","    return questions[:num_questions]"],"metadata":{"id":"CX7E6ZQEDbvQ","executionInfo":{"status":"ok","timestamp":1747232520469,"user_tz":-330,"elapsed":25,"user":{"displayName":"Ruchira Gamage","userId":"11748974728532815800"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["# Main Application"],"metadata":{"id":"Ylbim9Y5DiIe"}},{"cell_type":"code","source":["from google.colab import files\n","import time\n","\n","class QuizGenerator:\n","    def __init__(self):\n","        self.llm = llm\n","        self.current_text = \"\"\n","        self.questions = []\n","\n","    def upload_and_process(self):\n","        \"\"\"Handle PDF upload and processing\"\"\"\n","        print(\"📤 Upload a PDF file:\")\n","        uploaded = files.upload()\n","\n","        if not uploaded:\n","            print(\"No file uploaded!\")\n","            return False\n","\n","        file_name = next(iter(uploaded))\n","        print(f\"Processing {file_name}...\")\n","\n","        # Extract text\n","        self.current_text = pdf_to_text(uploaded[file_name])\n","        if not self.current_text:\n","            print(\"Failed to extract text from PDF\")\n","            return False\n","\n","        # Generate questions\n","        print(\"Generating questions...\")\n","        self.questions = generate_quiz(self.current_text)\n","        return True\n","\n","    def show_questions(self):\n","        \"\"\"Display generated questions\"\"\"\n","        if not self.questions:\n","            print(\"No questions generated yet\")\n","            return\n","\n","        print(\"\\nGenerated Questions:\")\n","        for i, q in enumerate(self.questions, 1):\n","            print(f\"\\nQuestion {i}:\")\n","            print(q)\n","            print(\"-\" * 50)\n","\n","    def chat_about_content(self):\n","        \"\"\"Chat about the PDF content\"\"\"\n","        if not self.current_text:\n","            print(\"No content available - upload a PDF first\")\n","            return\n","\n","        print(\"\\nChat about the content (type 'quit' to exit):\")\n","        while True:\n","            user_input = input(\"\\nYour question: \").strip()\n","            if user_input.lower() == 'quit':\n","                break\n","\n","            try:\n","                response = self.llm.create_chat_completion(\n","                    messages=[{\n","                        \"role\": \"system\",\n","                        \"content\": \"You're an assistant helping with document understanding.\"\n","                    },{\n","                        \"role\": \"user\",\n","                        \"content\": f\"Document content: {self.current_text[:3000]}\\n\\nQuestion: {user_input}\"\n","                    }],\n","                    max_tokens=500,\n","                    temperature=0.7\n","                )\n","                print(\"\\nAssistant:\", response['choices'][0]['message']['content'])\n","            except Exception as e:\n","                print(f\"Error: {str(e)}\")\n"],"metadata":{"id":"EEB71zDNDmcU","executionInfo":{"status":"ok","timestamp":1747232525186,"user_tz":-330,"elapsed":26,"user":{"displayName":"Ruchira Gamage","userId":"11748974728532815800"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["# Main Execution"],"metadata":{"id":"OUqcmr7lDvBj"}},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    generator = QuizGenerator()\n","\n","    if generator.upload_and_process():\n","        generator.show_questions()\n","        generator.chat_about_content()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"iCLP4TAYDyc9","executionInfo":{"status":"ok","timestamp":1747236023197,"user_tz":-330,"elapsed":3493232,"user":{"displayName":"Ruchira Gamage","userId":"11748974728532815800"}},"outputId":"5b04c425-d664-4702-c079-efc96ccdf0bc"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["📤 Upload a PDF file:\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-b99445b3-22df-42b1-a8a3-79bd6b9e6ff5\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-b99445b3-22df-42b1-a8a3-79bd6b9e6ff5\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving GC22BEDE250- Operation Dimension of Education.pdf to GC22BEDE250- Operation Dimension of Education.pdf\n","Processing GC22BEDE250- Operation Dimension of Education.pdf...\n","Generating questions...\n"]},{"output_type":"stream","name":"stderr","text":["\rProcessing text:   0%|          | 0/11 [00:00<?, ?it/s]llama_perf_context_print:        load time =  198151.62 ms\n","llama_perf_context_print: prompt eval time =  198150.65 ms /   534 tokens (  371.07 ms per token,     2.69 tokens per second)\n","llama_perf_context_print:        eval time =     841.20 ms /     1 runs   (  841.20 ms per token,     1.19 tokens per second)\n","llama_perf_context_print:       total time =  198994.49 ms /   535 tokens\n","Processing text:   9%|▉         | 1/11 [03:19<33:11, 199.11s/it]Llama.generate: 13 prefix-match hit, remaining 366 prompt tokens to eval\n","llama_perf_context_print:        load time =  198151.62 ms\n","llama_perf_context_print: prompt eval time =  123254.15 ms /   366 tokens (  336.76 ms per token,     2.97 tokens per second)\n","llama_perf_context_print:        eval time =    2023.78 ms /     3 runs   (  674.59 ms per token,     1.48 tokens per second)\n","llama_perf_context_print:       total time =  125282.52 ms /   369 tokens\n","Processing text:  18%|█▊        | 2/11 [05:24<23:21, 155.74s/it]Llama.generate: 13 prefix-match hit, remaining 379 prompt tokens to eval\n","llama_perf_context_print:        load time =  198151.62 ms\n","llama_perf_context_print: prompt eval time =  128298.45 ms /   379 tokens (  338.52 ms per token,     2.95 tokens per second)\n","llama_perf_context_print:        eval time =    1818.89 ms /     3 runs   (  606.30 ms per token,     1.65 tokens per second)\n","llama_perf_context_print:       total time =  130121.47 ms /   382 tokens\n","Processing text:  27%|██▋       | 3/11 [07:34<19:12, 144.08s/it]Llama.generate: 14 prefix-match hit, remaining 371 prompt tokens to eval\n","llama_perf_context_print:        load time =  198151.62 ms\n","llama_perf_context_print: prompt eval time =  122883.96 ms /   371 tokens (  331.22 ms per token,     3.02 tokens per second)\n","llama_perf_context_print:        eval time =  264046.55 ms /   385 runs   (  685.84 ms per token,     1.46 tokens per second)\n","llama_perf_context_print:       total time =  387358.83 ms /   756 tokens\n","Processing text:  36%|███▋      | 4/11 [14:02<28:01, 240.17s/it]Llama.generate: 14 prefix-match hit, remaining 390 prompt tokens to eval\n","llama_perf_context_print:        load time =  198151.62 ms\n","llama_perf_context_print: prompt eval time =  130635.76 ms /   390 tokens (  334.96 ms per token,     2.99 tokens per second)\n","llama_perf_context_print:        eval time =    1308.76 ms /     2 runs   (  654.38 ms per token,     1.53 tokens per second)\n","llama_perf_context_print:       total time =  131964.06 ms /   392 tokens\n","Processing text:  45%|████▌     | 5/11 [16:14<20:07, 201.18s/it]Llama.generate: 13 prefix-match hit, remaining 374 prompt tokens to eval\n","llama_perf_context_print:        load time =  198151.62 ms\n","llama_perf_context_print: prompt eval time =  124238.68 ms /   374 tokens (  332.19 ms per token,     3.01 tokens per second)\n","llama_perf_context_print:        eval time =   18799.49 ms /    29 runs   (  648.26 ms per token,     1.54 tokens per second)\n","llama_perf_context_print:       total time =  143055.74 ms /   403 tokens\n","Processing text:  55%|█████▍    | 6/11 [18:37<15:07, 181.46s/it]Llama.generate: 13 prefix-match hit, remaining 364 prompt tokens to eval\n","llama_perf_context_print:        load time =  198151.62 ms\n","llama_perf_context_print: prompt eval time =  124377.84 ms /   364 tokens (  341.70 ms per token,     2.93 tokens per second)\n","llama_perf_context_print:        eval time =  269697.32 ms /   396 runs   (  681.05 ms per token,     1.47 tokens per second)\n","llama_perf_context_print:       total time =  394492.46 ms /   760 tokens\n","Processing text:  64%|██████▎   | 7/11 [25:11<16:44, 251.13s/it]Llama.generate: 13 prefix-match hit, remaining 382 prompt tokens to eval\n","llama_perf_context_print:        load time =  198151.62 ms\n","llama_perf_context_print: prompt eval time =  129236.26 ms /   382 tokens (  338.31 ms per token,     2.96 tokens per second)\n","llama_perf_context_print:        eval time =     650.15 ms /     1 runs   (  650.15 ms per token,     1.54 tokens per second)\n","llama_perf_context_print:       total time =  129888.78 ms /   383 tokens\n","Processing text:  73%|███████▎  | 8/11 [27:21<10:37, 212.56s/it]Llama.generate: 13 prefix-match hit, remaining 386 prompt tokens to eval\n","llama_perf_context_print:        load time =  198151.62 ms\n","llama_perf_context_print: prompt eval time =  129414.38 ms /   386 tokens (  335.27 ms per token,     2.98 tokens per second)\n","llama_perf_context_print:        eval time =    9780.66 ms /    14 runs   (  698.62 ms per token,     1.43 tokens per second)\n","llama_perf_context_print:       total time =  139204.65 ms /   400 tokens\n","Processing text:  82%|████████▏ | 9/11 [29:41<06:19, 189.66s/it]Llama.generate: 14 prefix-match hit, remaining 373 prompt tokens to eval\n","llama_perf_context_print:        load time =  198151.62 ms\n","llama_perf_context_print: prompt eval time =  124420.22 ms /   373 tokens (  333.57 ms per token,     3.00 tokens per second)\n","llama_perf_context_print:        eval time =  181827.62 ms /   265 runs   (  686.14 ms per token,     1.46 tokens per second)\n","llama_perf_context_print:       total time =  306484.74 ms /   638 tokens\n","Processing text:  91%|█████████ | 10/11 [34:47<03:45, 225.77s/it]Llama.generate: 14 prefix-match hit, remaining 433 prompt tokens to eval\n","llama_perf_context_print:        load time =  198151.62 ms\n","llama_perf_context_print: prompt eval time =  145456.52 ms /   433 tokens (  335.93 ms per token,     2.98 tokens per second)\n","llama_perf_context_print:        eval time =     713.61 ms /     1 runs   (  713.61 ms per token,     1.40 tokens per second)\n","llama_perf_context_print:       total time =  146173.44 ms /   434 tokens\n","Processing text: 100%|██████████| 11/11 [37:14<00:00, 203.10s/it]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Generated Questions:\n","\n","Question 1:\n","1.\n","--------------------------------------------------\n","\n","Question 2:\n","Q1) Which of the following is an example of a macro-level policy that can regulate education systems?\n","    A) Compulsory education legislation\n","    B) Quality assurance structures\n","    C) Accreditation rules\n","    D) All of the above\n","\n","Answer: D) All of the above\n","\n","Explanation: Macro-level policies can include compulsory education legislation, quality assurance structures, and accreditation rules, which are all examples of regulating education systems.\n","\n","Q2) Which of the following macro-level choices determines the patterns of distribution of financial resources across and between regions, education levels, and special programs?\n","    A) Allocations of education's proportion of national budgets\n","    B) Sub-national governments' funding formulas\n","    C) Investment priorities (e.g., STEM education versus vocational training)\n","    D) All of the above\n","\n","Answer: A) Allocations of education's proportion of national budgets\n","\n","Explanation: Macro-level choices determine the patterns of distribution of financial resources across and between regions, education levels, and special programs, including allocations of education's proportion of national budgets.\n","\n","Q3) Which of the following macro-level choices often decides teacher training standards, certification, career development, and professional development?\n","    A) National standards and standard tests\n","    B) School building, facility standards, and the integration of technology\n","    C) Teacher professionalization policies\n","    D) All of the above\n","\n","Answer: C) Teacher professionalization policies\n","\n","Explanation: Macro-level choices often decide teacher training standards, certification, career development, and professional development, which are examples of teacher professionalization policies.\n","--------------------------------------------------\n","\n","Question 3:\n","1. According to the text, what is the purpose of the \"Teach Less, Learn More\" model in Singapore?\n","--------------------------------------------------\n","\n","Question 4:\n","Q1) What is one of the major challenges in macro-level educational decision making?\n","    A) Ensuring equitable distribution of resources\n","    B) Implementing policies at the local level\n","    C) Coordinating between national and local implementers\n","    D) Allocating resources based on electoral constituencies\n","    Answer: B\n","\n","Explanation: One of the major challenges in macro-level educational decision making is the unequal distribution of resources, particularly in developing countries where rural schools lack the necessary infrastructure, teachers, and study materials compared to urban schools.\n","\n","    Q2) What does the World Bank (2018) highlight in relation to resource allocation in education?\n","    A) Inefficient systems of allocation can create high wastage\n","    B) Most essential requirements in terms of education quality remain unmet\n","    C) Money is lost in areas outside of priority\n","    D) All of the above\n","    Answer: A\n","\n","Explanation: According to the World Bank (2018), inefficient systems of allocation can create high wastage, where money is lost in areas outside of priority while most essential requirements in terms of education quality remain unmet.\n","\n","    Q3) What is one of the reasons for policy implementation gaps in education?\n","    A) Weak coordination between national and local implementers\n","    B) Resistance from powerful stakeholders such as teachers' unions and civil leaders\n","    C) Lack of clear policies and guidelines\n","    D) All of the above\n","    Answer: B\n","\n","Explanation: One of the reasons for policy implementation gaps in education is the resistance from powerful stakeholders such as teachers' unions and civil leaders, which can hinder the effective implementation of good macro-level policies at the meso and micro levels.\n","--------------------------------------------------\n","\n","Question 5:\n","3 quiz questions generated from the given text are below:\n","--------------------------------------------------\n","\n","Question 6:\n","1. Which of the following is an example of a broader shift towards \"green skills\" in education, according to UNESCO's (2021) report on education for sustainable development?\n","A) Reforestation initiatives at school level\n","B) Partnership with environmental organizations\n","C) Scaling up teacher training and curriculum reform\n","D) Decentralization of education governance\n","\n","2. According to OECD (2018), what is essential for effective decentralization in education?\n","A) Clearly defined accountability mechanisms\n","B) Developing the capacity of local administrators\n","C) Retaining control by provincial governments\n","D) Granting schools significant autonomy in curriculum delivery\n","\n","3. Which of the following countries has pursued a more balanced approach to decentralization in education, according to the text?\n","A) Sweden\n","B) Canada\n","C) Norway\n","D) Denmark\n","\n","Explanation:\n","\n","These questions are designed to test the reader's comprehension of the text and their ability to identify key concepts and ideas. They provide an opportunity for the reader to apply their knowledge and reasoning skills, and to demonstrate their understanding of the text.\n","--------------------------------------------------\n","\n","Chat about the content (type 'quit' to exit):\n","\n","Your question: quit\n"]}]}]}